<!DOCTYPE html>
<html>
<head>
    <title>ZENG Yuan</title>

    <!-- Meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Styles -->
    <style>
	 #head_icon {
	 	    display: block;
		    background-color: ##f4f4f4;
		    border-radius: 50% !important;
		    overflow: hidden;
		    position: relative;
	 }
          body {
            font-family: 'sans-serif';
            font-size: 16px;
            background-color: #FFFFFF;
            color: #4F6071;
          }
          #header {
            background-color: #f4f4f4;
	    opacity: 75%;
	    background-image: url('imgs/sustech.jpg');

            display: flex;
            align-items: flex-end;
            padding-top:60px;
            padding-bottom:60px;
          }
          #footer {
            background-color: #FFFFFF;
            padding:60px;
          }
          #portrait {
            border: 3px solid white;
          }
          #header-text {
            margin-top: 60px;
            margin-left: 220px;
          }
          #header-text-name {
            font-size: 45px;
          }
          #header-text-email {
            font-size: 20px;
            font-style: italic;
          }
          .header-text-desc {
            font-size: 20px;
          }
          .vspace-top {
            margin-top: 30px;
          }
          .vspace-top-news {
              margin-top: 15px;
          }
          .paper-image {
            width: 150px;
          }
          .news-date {
              font-weight: bold;
          }
          .paper-title {
            font-weight: bold;
          }
          .paper-authors {
            font-style: italic;
          }

    </style>
</head>

<body>
    <div id='header'>
        <div class='container'>
            <div class='row'>
                <div class="col-sm-2 offset-sm-1" >
                    <img id="head_icon" src="https://scholar.googleusercontent.com/citations?view_op=view_photo&user=9JIiC2EAAAAJ&citpid=2" class='img-fluid'>
                </div>

                <div class="col">
                  <div id='header-text-name'>
                      ZENG Yuan
                  </div>
                  <div id='header-text-email'>
                        zengy3@sustech.edu.cn
                  </div>
                  <div>
                    <a href="https://github.com/mldemox">[GitHub]</a>
                    <a href="https://scholar.google.com/citations?user=9JIiC2EAAAAJ&hl=zh-CN&oi=sra">[Google Scholar]</a>
		    <a href="https://eee.sustech.edu.cn/?view=5661&jsid=16">[HomePage]</a>
                  </div>

                </div>
            </div>
        </div>
    </div>


    <div class='container'>
        <div class='row vspace-top'>
            <div class='col offset-sm-1'>
                <h2>Self-Introduction</h2>
		<div>
                I'm a research assistant professor at <a href="https://www.sustech.edu.cn/">Southern University of Science and Technology.</a> <br>	
		In 2010, I received my master's degree in signal processing from the <a href="https://dianzi.nwpu.edu.cn/">School of Electronic Information of Northwestern Polytechnical University.</a> 
		In 2015, I received my doctorate degree in speech signal processing from <a href="https://www.tudelft.nl/en/">Delft University of Technology.</a> <br>
		From 2015 to 2018, I worked as a researcher in machine learning and image restoration in <a href="https://www.tudelft.nl/en/">Delft University of Technology.</a>  <br>
		Since 2018, he has been engaged in the research work of machine learning and signal detection and repair in <a href="https://www.sustech.edu.cn/">Southern University of Science and Technology.</a>	, and is committed to solving practical problems by combining traditional signal processing methods and machine learning methods.
                </div>


		<div class='vspace-top'>
                    <h2>Work Experience</h2>
			<p>2017.9-, Research assistant Professor, Department of Electronic and Electrical Engineering, Southern University of Science and Technology</p>
			<p>2015-2017 Postdoctoral Researcher, Department of Pattern Recognition and Machine Vision, Delft University of Technology, Netherlands. </p>
			<p>2016-2017 Visiting Researcher, Department of Artificial Intelligence, University of Tilburg, Netherlands</p>
                </div>
		
		    
                <div class='vspace-top'>
                    <h1>Research field</h1>
			
			<a href="#" class="list-group-item active">Intelligent signal estimation and enhancement</a>
			<a href="#" class="list-group-item">Intelligent signal detection and reconstruction
</a>
			<a href="#" class="list-group-item">Machine Vision and Cultural Promotion
</a>
			<a href="#" class="list-group-item">Front end signal processing system in Industrial internet of things
</a>
                </div>

                <div class='vspace-top'>
                    <h2>Publications</h2>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='FactorFields/img/framework.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Factor Fields: A Unified Framework for Neural Fields and Beyond
                        </div>
                        <div class='paper-desc'>
                             Arxiv
                        </div>
                        <div class='paper-authors'>
                            <b>Anpei Chen</b>, Zexiang Xu, Xinyue Wei, Siyu Tang, Hao Su, Andreas Geiger
                        </div>
                        <div>
                            <a href="https://apchenstu.github.io/FactorFields/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2302.01226">[Paper]</a>
                            <a href="https://github.com/autonomousvision/factor-fields">[Code]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/DiF.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Dictionary Fields: Learning a Neural Basis Decomposition
                        </div>
                        <div class='paper-desc'>
                             SIGGRAPH 2023 (Journal Track)
                        </div>
                        <div class='paper-authors'>
                            <b>Anpei Chen</b>, Zexiang Xu, Xinyue Wei, Siyu Tang, Hao Su, Andreas Geiger
                        </div>
                        <div>
                            <a href="https://apchenstu.github.io/FactorFields/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2302.01226">[Paper]</a>
                            <a href="https://github.com/autonomousvision/factor-fields">[Code]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/SSDNeRF.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Single-Stage Diffusion NeRF: A Unified Approach to 3D Generation and Reconstruction
                        </div>
                        <div class='paper-desc'>
                             ICCV 2023
                        </div>
                        <div class='paper-authors'>
                            Hansheng Chen, Jiatao Gu, <b>Anpei Chen</b>, Wei Tian, Zhuowen Tu, Lingjie Liu, Hao Su
                        </div>
                        <div>
                            <a href="https://lakonik.github.io/ssdnerf/">[Project page]</a>
                            <a href="https://arxiv.org/abs/2304.06714">[Paper]</a>
                            <a href="https://github.com/Lakonik/SSDNeRF">[Code]</a>
                        </div>
                    </div>
                </div>

               <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/SDFStudio.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            SDFStudio: A Unified Framework for Surface Reconstruction
                        </div>
                        <div class='paper-desc'>
                             OpenSource Project
                        </div>
                        <div class='paper-authors'>
                             Zehao Yu, <b>Anpei Chen</b>, Bozidar Antic, Songyou Peng, Apratim Bhattacharyya,<br>
                             Michael Niemeyer, Siyu Tang, Torsten Sattler, Andreas Geiger
                        </div>
                        <div>
                            <a href="https://autonomousvision.github.io/sdfstudio/">[Project page]</a>
                            <a href="https://github.com/autonomousvision/sdfstudio">[Code]</a>
                            <a href="https://github.com/autonomousvision/sdfstudio/blob/master/docs/sdfstudio-methods.md">[Documentation]</a>
                            <a href="https://github.com/autonomousvision/sdfstudio/blob/master/docs/sdfstudio-data.md">[Dataset]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/NeRFPlayer.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            NeRFPlayer: A Streamable Dynamic Scene Representation with Decomposed Neural Radiance Fields
                        </div>
                        <div class='paper-desc'>
                             IEEE VR 2023 (TVCG Journal Track)
                        </div>
                        <div class='paper-authors'>
                             Liangchen Song, <b>Anpei Chen</b>, Zhong Li, Zhang Chen, Lele Chen, Junsong Yuan, Yi Xu, Andreas Geiger
                        </div>
                        <div>
                            <a href="https://lsongx.github.io/projects/nerfplayer.html">[Project page]</a>
                            <a href="https://arxiv.org/pdf/2210.15947">[Paper]</a>
                            <a href="https://lsongx.github.io/projects/nerfplayer.html">[Code]</a>
                            <a href="https://github.com/nerfstudio-project/nerfstudio/tree/main/nerfstudio/fields">[NerfStudio]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/tensorf.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            TensoRF: Tensorial Radiance Fields
                        </div>
                        <div class='paper-desc'>
			                 ECCV 2022 (final scores: 1, 1, 1)
                        </div>
                        <div class='paper-authors'>
                             <b>Anpei Chen*</b>, Zexiang Xu*, Andreas Geiger, Jingyi Yu, Hao Su
                        </div>
                        <div>
                            <a href="https://apchenstu.github.io/TensoRF">[Project page]</a>
                            <a href="https://arxiv.org/abs/2203.09517">[Paper]</a>
                            <a href="TensoRF/review.pdf">[Review]</a>
                            <a href="TensoRF/rebuttal.pdf">[Rebuttal]</a>
                            <a href="TensoRF/meta-review.pdf">[Meta-review]</a>
                            <a href="https://github.com/apchenstu/TensoRF">[Code]</a>
                            <a href="https://github.com/nerfstudio-project/nerfstudio/tree/main/nerfstudio/fields">[NerfStudio]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/ICARUS.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            ICARUS: A Lightweight Neural Plenoptic Rendering Architecture
                        </div>
                        <div class='paper-desc'>
                             Siggraph Asia 2022 (TOG Journal Track)
                        </div>
                        <div class='paper-authors'>
                             Chaolin Rao, Huangjie Yu, Haochuan Wan, Jindong Zhou, Yueyang Zheng, Yu Ma, <br>
                             <b>Anpei Chen</b>, Minye Wu, Binzhe Yuan, Pingqiang Zhou, Xin Lou, Jingyi Yu
                        </div>
                        <div>
                            <a href="https://dl.acm.org/doi/abs/10.1145/3550454.3555505">[Paper]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/PREF.gif' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            PREF: Phasorial Embedding Fields for Compact Neural Representation
                        </div>
                        <div class='paper-desc'>
                             Arxiv
                        </div>
                        <div class='paper-authors'>
                             Binbin Huang, Xinhao Yan, <b>Anpei Chen</b>, Shenghua Gao, Jingyi Yu
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2205.13524">[Paper]</a>
                            <a href="https://github.com/hbb1/PREF">[Code]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/AAAI2022.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Anisotropic Fourier Features for Image-Based Rendering and Relighting
                        </div>
                        <div class='paper-desc'>
			                 AAAI 2022 (Oral)
                        </div>
                        <div class='paper-authors'>
                            Huangjie Yu, <b>Anpei Chen</b>, Xin Chen, Lan Xu, Ziyu Shao, Jingyi Yu
                        </div>
                        <div>
                            <a href="https://aaai-2022.virtualchair.net/poster_aaai2220">[Project page]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/mvsnerf2.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo
                        </div>
                        <div class='paper-desc'>
			                 ICCV 2021
                        </div>
                        <div class='paper-authors'>
                            <b>Anpei Chen*</b>, Zexiang Xu*, Fuqiang Zhao, Xiaoshuai Zhang, Fanbo Xiang, Jingyi Yu, Hao Su
                        </div>
                        <div>
                            <a href="https://apchenstu.github.io/mvsnerf">[Project page]</a>
                            <a href="https://arxiv.org/abs/2103.15595">[Paper]</a>
                            <a href="https://github.com/apchenstu/mvsnerf">[Code]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/GNeRF.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            GNeRF: GAN-based Neural Radiance Field without Posed Camera
                        </div>
                        <div class='paper-desc'>
                       ICCV 2021 (Oral)
                        </div>
                        <div class='paper-authors'>
                            Quan Meng, <b>Anpei Chen</b>, Haimin Luo, Minye Wu, Hao Su, Lan Xu, Xuming He, Jingyi Yu
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2103.15606">[Paper]</a>
                            <a href="https://github.com/MQ66/gnerf">[Code]</a>
                            <a href="https://www.youtube.com/watch?v=pXnY9uSmEsw">[Video]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="imgs/ConvNeRF.mp4" type="video/mp4">
                        </video>
                    </div>
                    
                    <div class="col">
                        <div class='paper-title'>
                            ConvNeRF: Convolutional Neural Opacity Radiance Fields
                        </div>
                        <div class='paper-desc'>
                       ICCP 2021
                        </div>
                        <div class='paper-authors'>
                            Haimin Luo, <b>Anpei Chen</b>, Qixuan Zhang, Bai Pang, Minye Wu, Lan Xu, Jingyi Yu
                        </div>
                        <div>
                            <a href="https://arxiv.org/abs/2104.01772">[Paper]</a>
                        </div>
                    </div>
                </div>
                
                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                        <source src="imgs/sofgan.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          SofGAN: A Portrait Image Generator with Dynamic Styling
                      </div>
                      <div class='paper-desc'>
                          TOG
                      </div>
                      <div class='paper-authors'>
                          <b>Anpei Chen*</b>, Ruiyang Liu*, Ling Xie, Zhang Chen, Hao Su, Jingyi Yu
                      </div>
                      <div>
                            <a href="https://apchenstu.github.io/sofgan">[Project page]</a>
                            <a href="https://arxiv.org/abs/2007.03780">[Paper]</a>
                            <a href="https://github.com/apchenstu/sofgan">[Code]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/relighting.mp4" type="video/mp4">
                        </video>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          A neural rendering framework for free-viewpoint relighting
                      </div>
                      <div class='paper-desc'>
                          CVPR 2020
                      </div>
                      <div class='paper-authors'>
                          Zhang Chen, <b>Anpei Chen</b>, Guli Zhang, Chengyuan Wang, Yu Ji, Kiriakos N Kutulakos, Jingyi Yu
                      </div>
                      <div>
                            <a href="https://arxiv.org/abs/1911.11530">[Paper]</a>
                            <a href="https://github.com/LansburyCH/relightable-nr">[Code]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/facial_detail.png' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          Photo-Realistic Facial Details Synthesis from Single Image
                      </div>
                      <div class='paper-desc'>
                          ICCV 2019 (Oral)
                      </div>
                      <div class='paper-authors'>
                          <b>Anpei Chen</b>, Zhang Chen, Guli Zhang, Ziheng Zhang, Kenny Mitchell, Jingyi Yu
                      </div>
                      <div>
                            <a href="https://apchenstu.github.io/facial_details/">[Project page]</a>
                            <a href="https://arxiv.org/abs/1903.10873">[Paper]</a>
                            <a href="https://github.com/apchenstu/Facial_Details_Synthesis">[Code]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                            <source src="imgs/3d_face.mp4" type="video/mp4">
                        </video>
                    </div>


                    <div class="col">
                      <div class='paper-title'>
                          Sparse photometric 3d face reconstruction guided by morphable models
                      </div>
                      <div class='paper-desc'>
                          CVPR 2019
                      </div>
                      <div class='paper-authors'>
                          Xuan Cao, Zhang Chen, <b>Anpei Chen</b>, Xin Chen, Shiying Li, Jingyi Yu
                      </div>
                      <div>
                            <a href="https://arxiv.org/abs/1711.10870">[Paper]</a>
                      </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/amodal.png' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          Learning semantics-aware distance map with semantics layering network for amodal instance segmentation
                      </div>
                      <div class='paper-desc'>
                          ACM MM 2019
                      </div>
                      <div class='paper-authors'>
                          Ziheng Zhang*, <b>Anpei Chen*</b>, Ling Xie, Jingyi Yu, Shenghua Gao
                      </div>
                      <div>
                            <a href="https://arxiv.org/abs/1905.12898">[Paper]</a>
                            <a href="https://github.com/apchenstu/SLN-Amodal">[Code]</a>
                      </div>
                    </div>
                </div>

               <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/refocusable.jpg' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          Refocusable Gigapixel Panoramas for Immersive VR Experiences
                      </div>
                      <div class='paper-desc'>
                          TVCG 2019
                      </div>
                      <div class='paper-authors'>
                          Wentao Lyu, Peng Ding, Yingliang Zhang, <b>Anpei Chen</b>, Minye Wu, Shu Yin, Jingyi Yu
                      </div>
                      <div>
                            <a href="https://ieeexplore.ieee.org/iel7/2945/4359476/08827949.pdf">[Paper]</a>
                      </div>
                    </div>
                </div>

               <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='imgs/dslf.png' class='img-fluid'>
                    </div>

                    <div class="col">
                      <div class='paper-title'>
                          Deep surface light fields
                      </div>
                      <div class='paper-desc'>
                          I3D 2018
                      </div>
                      <div class='paper-authors'>
                          <b>Anpei Chen</b>, Minye Wu, Yingliang Zhang, Nianyi Li, Jie Lu, Shenghua Gao, Jingyi Yu
                      </div>
                      <div>
                            <a href="https://apchenstu.github.io/dslf">[Project page]</a>
                            <a href="https://arxiv.org/abs/1810.06514">[Paper]</a>
                      </div>
                    </div>
                </div>
            </div>
        </div>
    </div>



                

    <div id='footer' class='vspace-top'>
    <div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>

</html>
